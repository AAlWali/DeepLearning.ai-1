{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "-G2qYpEJs0mU",
        "colab_type": "code",
        "outputId": "1c0f4b60-74c5-4654-e481-3fccddfca259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sys\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "_RQ9olrxtwS6",
        "colab_type": "code",
        "outputId": "93d471c6-9518-463d-b2ff-d17653375e40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir -p drive "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dxTgoxEbxs_D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os import listdir\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zOo5GUNjtA48",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DCGAN():\n",
        "    def __init__(self):\n",
        "        # Input shape\n",
        "        self.img_rows = 128\n",
        "        self.img_cols = 128\n",
        "        self.channels = 3\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        self.latent_dim = 100\n",
        "        self.train_path='/content/drive/My Drive/images/'\n",
        "\n",
        "        optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "        # Build and compile the discriminator\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.discriminator.compile(loss='binary_crossentropy',\n",
        "            optimizer=optimizer,\n",
        "            metrics=['accuracy'])\n",
        "\n",
        "        # Build the generator\n",
        "        self.generator = self.build_generator()\n",
        "\n",
        "        # The generator takes noise as input and generates imgs\n",
        "        z = Input(shape=(self.latent_dim,))\n",
        "        img = self.generator(z)\n",
        "\n",
        "        # For the combined model we will only train the generator\n",
        "        self.discriminator.trainable = False\n",
        "\n",
        "        # The discriminator takes generated images as input and determines validity\n",
        "        valid = self.discriminator(img)\n",
        "\n",
        "        # The combined model  (stacked generator and discriminator)\n",
        "        # Trains the generator to fool the discriminator\n",
        "        self.combined = Model(z, valid)\n",
        "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "    \n",
        "    #load the required dataset. \n",
        "    def load_dataset(self,train_path):\n",
        "        images=os.listdir(train_path)\n",
        "        X=[]\n",
        "        image_size=128\n",
        "        for img in images:\n",
        "          img=os.path.join(train_path,img)\n",
        "          #print(img)\n",
        "          image = cv2.imread(img)\n",
        "          image = cv2.resize(image, (image_size, image_size), cv2.INTER_LINEAR)\n",
        "          image = image.astype(np.float32)\n",
        "          image = np.multiply(image, 1.0 / 255.0)\n",
        "          X.append(image)\n",
        "        X_train=np.array(X)\n",
        "        print(X_train.shape)\n",
        "        print(\"Data loaded\")\n",
        "        return X_train\n",
        "\n",
        "    def build_generator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Dense(128 * 128 * 3, activation=\"relu\", input_dim=self.latent_dim))\n",
        "        model.add(Reshape((128,128,3)))\n",
        "        #model.add(UpSampling2D())\n",
        "        #model.summary()\n",
        "        \n",
        "        model.add(Conv2D(1024, kernel_size=4,padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        #model.add(UpSampling2D())\n",
        "        \n",
        "        model.add(Conv2D(512, kernel_size=8, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        #model.add(UpSampling2D())\n",
        "        \n",
        "        model.add(Conv2D(256, kernel_size=16,padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        #model.add(UpSampling2D())\n",
        "        \n",
        "        model.add(Conv2D(128, kernel_size=32, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        #model.add(UpSampling2D())\n",
        "        \n",
        "        model.add(Conv2D(3, kernel_size=3, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        \n",
        "        model.add(Conv2D(1024, kernel_size=3,padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        \n",
        "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
        "        model.add(Activation(\"tanh\"))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        noise = Input(shape=(self.latent_dim,))\n",
        "        img = model(noise)\n",
        "        print(\"im_shape=\",img.shape)\n",
        "\n",
        "        return Model(noise, img)\n",
        "\n",
        "    def build_discriminator(self):\n",
        "\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Conv2D(1024, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        \n",
        "        model.add(Conv2D(512, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        \n",
        "        model.add(Conv2D(256, kernel_size=3, strides=2, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        \n",
        "        model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        \n",
        "        model.add(Conv2D(64, kernel_size=3, strides=1, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        \n",
        "        model.add(Conv2D(32, kernel_size=3, strides=1, padding=\"same\"))\n",
        "        model.add(BatchNormalization(momentum=0.8))\n",
        "        model.add(LeakyReLU(alpha=0.2))\n",
        "        model.add(Dropout(0.25))\n",
        "        \n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        img = Input(shape=self.img_shape)\n",
        "        validity = model(img)\n",
        "\n",
        "        return Model(img, validity)\n",
        "\n",
        "    def train(self, epochs, batch_size=128, save_interval=50):\n",
        "\n",
        "        # Load the dataset\n",
        "        X_train = self.load_dataset(self.train_path)\n",
        "        #(X_train, _), (_, _) = mnist.load_data()\n",
        "        print(X_train.shape)\n",
        "\n",
        "        # Rescale -1 to 1\n",
        "        X_train = X_train / 127.5 - 1.\n",
        "        #X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = np.ones((batch_size, 1))\n",
        "        fake = np.zeros((batch_size, 1))\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Discriminator\n",
        "            # ---------------------\n",
        "\n",
        "            # Select a random half of images\n",
        "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "            print(\"X_train.shape[0]=\",X_train.shape[0])\n",
        "            imgs = X_train[idx]\n",
        "            print(imgs[0].shape)\n",
        "            print(imgs.shape,valid.shape)\n",
        "\n",
        "            # Sample noise and generate a batch of new images\n",
        "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "            print(\"noise shape=\",noise.shape)\n",
        "            gen_imgs = self.generator.predict(noise)\n",
        "            print(\"gen imgs shape=\",gen_imgs.shape)\n",
        "            # Train the discriminator (real classified as ones and generated as zeros)\n",
        "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
        "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # ---------------------\n",
        "            #  Train Generator\n",
        "            # ---------------------\n",
        "\n",
        "            # Train the generator (wants discriminator to mistake images as real)\n",
        "            g_loss = self.combined.train_on_batch(noise, valid)\n",
        "\n",
        "            # Plot the progress\n",
        "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
        "\n",
        "            # If at save interval => save generated image samples\n",
        "            if epoch % save_interval == 0:\n",
        "                self.save_imgs(epoch)\n",
        "\n",
        "    def save_imgs(self, epoch):\n",
        "        r, c = 10, 10\n",
        "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "        # Rescale images 0 - 1\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "        fig, axs = plt.subplots(r, c)\n",
        "        cnt = 0\n",
        "        for i in range(r):\n",
        "            for j in range(c):\n",
        "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
        "                axs[i,j].axis('off')\n",
        "                cnt += 1\n",
        "        fig.savefig(\"/content/drive/My Drive/pictures/TASK_%d.png\" % epoch)\n",
        "        plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2FEyPosntIM2",
        "colab_type": "code",
        "outputId": "3c56a145-ffc6-4dba-eee3-6e6e331ba589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2094
        }
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    dcgan = DCGAN()\n",
        "    #dcgan.build_generator()\n",
        "    dcgan.train(epochs=400, batch_size=32, save_interval=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 64, 64, 1024)      28672     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 1024)      0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64, 64, 1024)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 512)       4719104   \n",
            "_________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPaddin (None, 33, 33, 512)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 33, 33, 512)       2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 33, 33, 512)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 33, 33, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 17, 17, 256)       1179904   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 17, 17, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 17, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 17, 17, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 17, 17, 128)       295040    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 17, 17, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 17, 17, 64)        73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 17, 17, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 17, 17, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 17, 17, 32)        18464     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 17, 17, 32)        128       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 17, 17, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 17, 17, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9248)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 9249      \n",
            "=================================================================\n",
            "Total params: 6,328,193\n",
            "Trainable params: 6,326,209\n",
            "Non-trainable params: 1,984\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 49152)             4964352   \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 128, 128, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 128, 128, 32)      896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 128, 128, 32)      128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 128, 128, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 128, 128, 64)      18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 128, 128, 64)      256       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 128, 128, 128)     512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 128, 128, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 128, 128, 256)     295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 128, 128, 256)     1024      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 128, 128, 256)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 128, 128, 512)     1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 128, 128, 512)     2048      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 128, 128, 512)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 128, 128, 1024)    4719616   \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 128, 128, 1024)    4096      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 128, 128, 1024)    0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 128, 128, 3)       27651     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 128, 128, 3)       0         \n",
            "=================================================================\n",
            "Total params: 11,288,259\n",
            "Trainable params: 11,284,227\n",
            "Non-trainable params: 4,032\n",
            "_________________________________________________________________\n",
            "im_shape= (?, 128, 128, 3)\n",
            "(1819, 128, 128, 3)\n",
            "Data loaded\n",
            "(1819, 128, 128, 3)\n",
            "X_train.shape[0]= 1819\n",
            "(128, 128, 3)\n",
            "(32, 128, 128, 3) (32, 1)\n",
            "noise shape= (32, 100)\n",
            "gen imgs shape= (32, 128, 128, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}