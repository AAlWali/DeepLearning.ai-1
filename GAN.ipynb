{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishant-sethi/DeepLearning.ai/blob/master/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5lATslh62lRI",
        "colab_type": "code",
        "outputId": "aa9d505a-ffa3-4a89-a086-80cc47dbcdff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Nishant\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nishant\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KUh2J_N7tAry",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yqdyHo4es_et",
        "colab_type": "code",
        "outputId": "9ce4679b-a9eb-4893-97b7-d0d1dfd04a7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir -p drive \n",
        "from keras.layers import Input\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers.core import Reshape, Dense, Dropout, Flatten\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import Convolution2D, UpSampling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "from keras import initializers\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "YyWy54iht8RP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os import listdir\n",
        "import cv2\n",
        "import numpy as np\n",
        "train_path='/content/drive/My Drive/images/'\n",
        "def load_dataset():\n",
        "    images=os.listdir(train_path)\n",
        "    X=[]\n",
        "    image_size=128\n",
        "    for img in images:\n",
        "      img=os.path.join(train_path,img)\n",
        "#       print(img)\n",
        "      image = cv2.imread(img)\n",
        "      image = cv2.resize(image, (image_size, image_size), cv2.INTER_LINEAR)\n",
        "      image = image.astype(np.float32)\n",
        "      image = np.multiply(image, 1.0 / 255.0)\n",
        "      X.append(image)\n",
        "    X_train=np.array(X).reshape(1819,49152)\n",
        "    print(X_train.shape)\n",
        "    print(\"Data loaded\")\n",
        "    return X_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1lGcEkA7al4m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "1c6c1110-47c7-4ddb-8a62-4540820de183"
      },
      "cell_type": "code",
      "source": [
        "load_dataset()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1819, 49152)\n",
            "Data loaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
              "        1.        ],\n",
              "       [0.77647066, 0.7607844 , 0.7568628 , ..., 0.73333335, 0.7176471 ,\n",
              "        0.7137255 ],\n",
              "       [1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
              "        1.        ],\n",
              "       ...,\n",
              "       [1.        , 1.        , 1.        , ..., 1.        , 1.        ,\n",
              "        1.        ],\n",
              "       [0.7803922 , 0.76470596, 0.7607844 , ..., 0.7490196 , 0.73333335,\n",
              "        0.7294118 ],\n",
              "       [0.77647066, 0.7607844 , 0.7568628 , ..., 0.7372549 , 0.72156864,\n",
              "        0.7176471 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "0jZ13SptTM-I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "randomDim = 100\n",
        "adam = Adam(lr=0.0002, beta_1=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V0w_09nsLo-c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_generator():\n",
        "  generator = Sequential()\n",
        "  generator.add(Dense(256, input_dim=randomDim, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "  generator.add(LeakyReLU(0.2))\n",
        "  generator.add(Dense(512))\n",
        "  generator.add(LeakyReLU(0.2))\n",
        "  generator.add(Dense(1024))\n",
        "  generator.add(LeakyReLU(0.2))\n",
        "  generator.add(Dense(2048))\n",
        "  generator.add(LeakyReLU(0.2))\n",
        "  generator.add(Dense(49152, activation='tanh'))\n",
        "  generator.compile(loss='binary_crossentropy', optimizer=adam)\n",
        "  print(\"Generator is Ready\")\n",
        "  return generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZaZFBJsZLsrt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_discriminator():\n",
        "  discriminator = Sequential()\n",
        "  discriminator.add(Dense(1024, input_dim=49152, kernel_initializer=initializers.RandomNormal(stddev=0.02)))\n",
        "  discriminator.add(LeakyReLU(0.2))\n",
        "  discriminator.add(Dropout(0.3))\n",
        "  discriminator.add(Dense(512))\n",
        "  discriminator.add(LeakyReLU(0.2))\n",
        "  discriminator.add(Dropout(0.3))\n",
        "  discriminator.add(Dense(256))\n",
        "  discriminator.add(LeakyReLU(0.2))\n",
        "  discriminator.add(Dropout(0.3))\n",
        "  discriminator.add(Dense(1, activation='sigmoid'))\n",
        "  discriminator.compile(loss='binary_crossentropy', optimizer=adam)\n",
        "  print(\"Discriminator is ready\")\n",
        "  return discriminator\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WMqFfd36Lwlg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def model_GAN():\n",
        "  # Combined network\n",
        "  discriminator.trainable = False\n",
        "  ganInput = Input(shape=(randomDim,))\n",
        "  x = generator(ganInput)\n",
        "  ganOutput = discriminator(x)\n",
        "  gan = Model(inputs=ganInput, outputs=ganOutput)\n",
        "  gan.compile(loss='binary_crossentropy', optimizer=adam)\n",
        "  return gan"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WLoO_E4uL2Bu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "epochs,batchSize=40,128\n",
        "def train_model(X_train,generator,discriminator,gan):\n",
        "    print(\"Training started\")\n",
        "    batchCount = X_train.shape[0] // batchSize\n",
        "    print('Epochs:', epochs)\n",
        "    print ('Batch size:', batchSize)\n",
        "    print ('Batches per epoch:', batchCount)\n",
        "\n",
        "    for e in range(1, epochs+1):\n",
        "        print ('-'*15, 'Epoch %d' % e, '-'*15)\n",
        "        for _ in tqdm(range(batchCount)):\n",
        "            # Get a random set of input noise and images\n",
        "            noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
        "            imageBatch = X_train[np.random.randint(0, X_train.shape[0], size=batchSize)]\n",
        "\n",
        "            # Generate fake MNIST images\n",
        "            generatedImages = generator.predict(noise)\n",
        "            print(np.shape(imageBatch), np.shape(generatedImages))\n",
        "            X = np.concatenate([imageBatch, generatedImages])\n",
        "\n",
        "            # Labels for generated and real data\n",
        "            yDis = np.zeros(2*batchSize)\n",
        "            # One-sided label smoothing\n",
        "            yDis[:batchSize] = 0.9\n",
        "\n",
        "            # Train discriminator\n",
        "            discriminator.trainable = True\n",
        "            dloss = discriminator.train_on_batch(X, yDis)\n",
        "\n",
        "            # Train generator\n",
        "            noise = np.random.normal(0, 1, size=[batchSize, randomDim])\n",
        "            yGen = np.ones(batchSize)\n",
        "            discriminator.trainable = False\n",
        "            gloss = gan.train_on_batch(noise, yGen)\n",
        "\n",
        "        # Store loss of most recent batch from this epoch\n",
        "        dLosses.append(dloss)\n",
        "        gLosses.append(gloss)\n",
        "\n",
        "        if e == 1 or e % 20 == 0:\n",
        "            plotGeneratedImages(e)\n",
        "            saveModels(e,generator,discriminator)\n",
        "\n",
        "    # Plot losses from every epoch\n",
        "    plotLoss(e)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7IDYMWj5L9xG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dLosses = []\n",
        "gLosses = []\n",
        "def plotLoss(epoch):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.plot(dLosses, label='Discriminitive loss')\n",
        "    plt.plot(gLosses, label='Generative loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('/content/drive/My Drive/images/gan_loss_epoch_%d.png' % epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16ilIIrVMF6i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plotGeneratedImages(epoch, examples=100, dim=(10, 10), figsize=(10, 10)):\n",
        "    noise = np.random.normal(0, 1, size=[examples, randomDim])\n",
        "    generatedImages = generator.predict(noise)\n",
        "    generatedImages = generatedImages.reshape(examples, 128, 128,3)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(generatedImages.shape[0]):\n",
        "        plt.subplot(dim[0], dim[1], i+1)\n",
        "        plt.imshow(generatedImages[i], interpolation='nearest', cmap='gray_r')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('/content/drive/My Drive/generated_images/gan_generated_image_epoch_%d.png' % epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FzuCF76wSCj1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def saveModels(epoch,generator,discriminator):\n",
        "    generator.save('/content/drive/My Drive/models/gan_generator_epoch_%d.h5' % epoch)\n",
        "    discriminator.save('/content/drive/My Drive/models/gan_discriminator_epoch_%d.h5' % epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eq2Lxk0pNYYH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "1ab3a834-9b1a-43e1-8ece-87df01403321"
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    X_train=load_dataset()\n",
        "    generator=load_generator()\n",
        "    discriminator=load_discriminator()\n",
        "    gan=model_GAN()\n",
        "    train_model(X_train,generator,discriminator,gan)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-49495adfa77f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdiscriminator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mgan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_GAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-ffc654fe6337>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#       print(img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(3.4.3) /io/opencv/modules/imgproc/src/resize.cpp:4044: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ]
    }
  ]
}